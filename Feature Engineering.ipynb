{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "## on mac run `brew install lightgbm` \n",
    "## anythign else refer here https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#apple-clang\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/application_train.csv\")\n",
    "test_df = pd.read_csv(\"./data/application_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-286c6ff8d1a2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['DAYS_EMPLOYED'][train_df['DAYS_EMPLOYED'] == 365243] = np.nan\n",
      "<ipython-input-53-286c6ff8d1a2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['DAYS_EMPLOYED'][test_df['DAYS_EMPLOYED'] == 365243] = np.nan\n"
     ]
    }
   ],
   "source": [
    "## clean up some rows\n",
    "train_df['DAYS_EMPLOYED'][train_df['DAYS_EMPLOYED'] == 365243] = np.nan\n",
    "test_df['DAYS_EMPLOYED'][test_df['DAYS_EMPLOYED'] == 365243] = np.nan\n",
    "train_df['OBS_30_CNT_SOCIAL_CIRCLE'][train_df['OBS_30_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
    "train_df['OBS_60_CNT_SOCIAL_CIRCLE'][train_df['OBS_60_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
    "test_df['OBS_30_CNT_SOCIAL_CIRCLE'][test_df['OBS_30_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
    "test_df['OBS_60_CNT_SOCIAL_CIRCLE'][test_df['OBS_60_CNT_SOCIAL_CIRCLE'] > 30] == np.nan\n",
    "train_df = train_df[train_df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "## remove rows with only 1 distinct value\n",
    "empty_columns = []\n",
    "for col in train_df.columns:\n",
    "    if len(train_df[col].unique()) <=1:\n",
    "        empty_columns.append(col)\n",
    "train_df = train_df.drop(empty_columns, axis = 1)\n",
    "test_df = test_df.drop(empty_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## other pre-processing\n",
    "train_df[\"DAYS_BIRTH\"] = train_df[\"DAYS_BIRTH\"] * -1 / 365\n",
    "test_df[\"DAYS_BIRTH\"] = test_df[\"DAYS_BIRTH\"] * -1 / 365\n",
    "categorical_columns = train_df.dtypes[train_df.dtypes == \"object\"].index.tolist()\n",
    "train_df[categorical_columns] = train_df[categorical_columns].fillna(\"XNA\")\n",
    "test_df[categorical_columns] = test_df[categorical_columns].fillna(\"XNA\")\n",
    "train_df[\"REGION_RATING_CLIENT\"] = train_df[\"REGION_RATING_CLIENT\"].astype(\"object\")\n",
    "train_df[\"REGION_RATING_CLIENT_W_CITY\"] = train_df[\n",
    "    \"REGION_RATING_CLIENT_W_CITY\"\n",
    "].astype(\"object\")\n",
    "test_df[\"REGION_RATING_CLIENT\"] = test_df[\"REGION_RATING_CLIENT\"].astype(\"object\")\n",
    "test_df[\"REGION_RATING_CLIENT_W_CITY\"] = test_df[\"REGION_RATING_CLIENT_W_CITY\"].astype(\n",
    "    \"object\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cols = \"NAME_CONTRACT_TYPE, CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_TYPE_SUITE, NAME_INCOME_TYPE, NAME_EDUCATION_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE, REGION_RATING_CLIENT, REGION_RATING_CLIENT_W_CITY, WEEKDAY_APPR_PROCESS_START, ORGANIZATION_TYPE, FONDKAPREMONT_MODE, HOUSETYPE_MODE, WALLSMATERIAL_MODE, EMERGENCYSTATE_MODE\".split(\", \")\n",
    "for c in bad_cols:\n",
    "    train_df[c] = train_df[c].astype(\"category\")\n",
    "    test_df[c] = test_df[c].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 122)\n",
      "(48744, 121)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "target_df = train_df.pop(\"TARGET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using LightGBM for recursive feature selection\n",
    "def cut_down_features(train_df, test_df):\n",
    "    num_folds = 3\n",
    "    impt_cols = set()\n",
    "    score = 1\n",
    "    i = 1\n",
    "    while score > 0.72:\n",
    "        selection_data = train_df.drop(list(impt_cols), axis=1)\n",
    "        fold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=33)\n",
    "        score = 0\n",
    "        model_feature_importance = np.zeros_like(selection_data.columns)\n",
    "        for fold_num, (train_indices, val_indices) in enumerate(\n",
    "            fold.split(selection_data, target_df), 1\n",
    "        ):\n",
    "            x_train = selection_data.iloc[train_indices]\n",
    "            x_val = selection_data.iloc[val_indices]\n",
    "            y_train = target_df.iloc[train_indices]\n",
    "            y_val = target_df.iloc[val_indices]\n",
    "            lg = LGBMClassifier(n_jobs=-1, random_state=69)\n",
    "            lg.fit(x_train, y_train)\n",
    "            model_feature_importance += lg.feature_importances_ / num_folds\n",
    "            score += roc_auc_score(y_val, lg.predict_proba(x_val)[:, 1]) / num_folds\n",
    "        imp_cols_indices = np.where(np.abs(model_feature_importance) > 0)\n",
    "        cols_imp = train_df.columns[imp_cols_indices]\n",
    "        if score > 0.7:\n",
    "            impt_cols.update(cols_imp)\n",
    "        i += 1\n",
    "    impt_cols = list(impt_cols)\n",
    "    train_df = train_df[impt_cols]\n",
    "    test_df = test_df[impt_cols]\n",
    "    with open(\"final_cols.pkl\", \"wb\") as f:\n",
    "        pickle.dump(train_df.columns.tolist(), f)\n",
    "    gc.collect()\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "reduced_train_df, reduced_test_df = cut_down_features(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df.columns))\n",
    "print(len(reduced_train_df.columns))\n",
    "#lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | colsam... | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.NAME_HOUSING_TYPE, FLAG_OWN_REALTY, REGION_RATING_CLIENT_W_CITY, REGION_RATING_CLIENT, ORGANIZATION_TYPE, FONDKAPREMONT_MODE, OCCUPATION_TYPE, NAME_EDUCATION_TYPE, CODE_GENDER, NAME_FAMILY_STATUS, NAME_TYPE_SUITE, NAME_CONTRACT_TYPE, WALLSMATERIAL_MODE, NAME_INCOME_TYPE, HOUSETYPE_MODE, FLAG_OWN_CAR, WEEKDAY_APPR_PROCESS_START",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.3651758006703006, 0.9801591439928512, 0.741929990231823, 0.3940181611984513, 10.311238298072531, 26.415817659859908, 0.2589264827384402, 0.013288945884801236, 0.5541738669753602)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-581a209dbc40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m )\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mbopt_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-581a209dbc40>\u001b[0m in \u001b[0;36mxgb_evaluation\u001b[0;34m(max_depth, min_child_weight, gamma, subsample, colsample_bytree, colsample_bylevel, colsample_bynode, reg_alpha, reg_lambda)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mxgbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         xgbc.fit(\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please reshape the input data X into 2-dimensional matrix.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m   1159\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, label_transform)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \"\"\"\n\u001b[0;32m--> 236\u001b[0;31m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m             \u001b[0mlabel_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch_data_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0m\u001b[1;32m    574\u001b[0m                                feature_names, feature_types)\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    256\u001b[0m def _from_pandas_df(data, enable_categorical, missing, nthread,\n\u001b[1;32m    257\u001b[0m                     feature_names, feature_types):\n\u001b[0;32m--> 258\u001b[0;31m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[0m\u001b[1;32m    259\u001b[0m         data, enable_categorical, feature_names, feature_types)\n\u001b[1;32m    260\u001b[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mcategorical\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msupplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 `enable_categorical` must be set to `True`.\"\"\"\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.NAME_HOUSING_TYPE, FLAG_OWN_REALTY, REGION_RATING_CLIENT_W_CITY, REGION_RATING_CLIENT, ORGANIZATION_TYPE, FONDKAPREMONT_MODE, OCCUPATION_TYPE, NAME_EDUCATION_TYPE, CODE_GENDER, NAME_FAMILY_STATUS, NAME_TYPE_SUITE, NAME_CONTRACT_TYPE, WALLSMATERIAL_MODE, NAME_INCOME_TYPE, HOUSETYPE_MODE, FLAG_OWN_CAR, WEEKDAY_APPR_PROCESS_START"
     ]
    }
   ],
   "source": [
    "def xgb_evaluation(\n",
    "    max_depth,\n",
    "    min_child_weight,\n",
    "    gamma,\n",
    "    subsample,\n",
    "    colsample_bytree,\n",
    "    colsample_bylevel,\n",
    "    colsample_bynode,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "):\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "        \"gpu_id\": 0,\n",
    "        \"max_depth\": int(round(max_depth)),\n",
    "        \"min_child_weight\": int(round(min_child_weight)),\n",
    "        \"subsample\": subsample,\n",
    "        \"gamma\": gamma,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"colsample_bylevel\": colsample_bylevel,\n",
    "        \"colsample_bynode\": colsample_bynode,\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"random_state\": 51412,\n",
    "        \"enable_categorical\": True\n",
    "    }\n",
    "\n",
    "    # defining the Cross-Validation Strategry\n",
    "    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=33)\n",
    "    cv_preds = np.zeros(reduced_train_df.shape[0])\n",
    "\n",
    "    # iterating over each fold, training the model, and making Out of Fold Predictions\n",
    "    for train_indices, cv_indices in stratified_cv.split(reduced_train_df, target_df):\n",
    "\n",
    "        x_tr = reduced_train_df.iloc[train_indices]\n",
    "        y_tr = target_df.iloc[train_indices]\n",
    "        x_cv = reduced_train_df.iloc[cv_indices]\n",
    "        y_cv = target_df.iloc[cv_indices]\n",
    "\n",
    "        xgbc = XGBClassifier(**params)\n",
    "        xgbc.fit(\n",
    "            x_tr,\n",
    "            y_tr,\n",
    "            eval_set=[(x_cv, y_cv)],\n",
    "            eval_metric=\"auc\",\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "\n",
    "        cv_preds[cv_indices] = xgbc.predict_proba(\n",
    "            x_cv, ntree_limit=xgbc.get_booster().best_ntree_limit\n",
    "        )[:, 1]\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(target_df, cv_preds)\n",
    "\n",
    "bopt_xgb = BayesianOptimization(\n",
    "    xgb_evaluation,\n",
    "    {\n",
    "        \"max_depth\": (5, 15),\n",
    "        \"min_child_weight\": (5, 80),\n",
    "        \"gamma\": (0.2, 1),\n",
    "        \"subsample\": (0.5, 1),\n",
    "        \"colsample_bytree\": (0.5, 1),\n",
    "        \"colsample_bylevel\": (0.3, 1),\n",
    "        \"colsample_bynode\": (0.3, 1),\n",
    "        \"reg_alpha\": (0.001, 0.3),\n",
    "        \"reg_lambda\": (0.001, 0.3),\n",
    "    },\n",
    "    random_state=55,\n",
    ")\n",
    "bopt_xgb.maximize(n_iter=6, init_points=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
